const fs = require('fs');
const path = require('path');
const { execSync } = require('child_process');

// T√™n plugin
const pluginName = 'ai-assistant';
const pluginVersion = '1.0.0';
const zipFileName = `${pluginName}-${pluginVersion}-complete.zip`;
const zipFilePath = path.join(__dirname, '..', zipFileName);

console.log('üöÄ ƒê√≥ng g√≥i AI Assistant Plugin HO√ÄN CH·ªàNH...');

// T·∫°o th∆∞ m·ª•c t·∫°m th·ªùi
const tempDir = path.join(__dirname, 'temp-complete-package');
if (fs.existsSync(tempDir)) {
  fs.rmSync(tempDir, { recursive: true, force: true });
}
fs.mkdirSync(tempDir, { recursive: true });

console.log('üì¶ T·∫°o package.json v·ªõi dependencies ƒë·∫ßy ƒë·ªß...');

// T·∫°o package.json ho√†n ch·ªânh
const packageJson = {
  "name": "ai-assistant",
  "version": "1.0.0",
  "description": "AI Assistant plugin for Text Editor with full AI capabilities",
  "main": "index.js",
  "scripts": {
    "start": "node index.js"
  },
  "author": "nhutwm",
  "license": "MIT",
  "dependencies": {
    "axios": "^1.6.2",
    "dotenv": "^16.3.1"
  }
};

fs.writeFileSync(
  path.join(tempDir, 'package.json'),
  JSON.stringify(packageJson, null, 2)
);

console.log('üß† T·∫°o index.js v·ªõi AI functions ho√†n ch·ªânh...');

// T·∫°o index.js ho√†n ch·ªânh v·ªõi t·∫•t c·∫£ AI functions
const indexJs = `// AI Assistant Plugin - Complete Version
const net = require('net');
const axios = require('axios');
const dotenv = require('dotenv');

// Load environment variables
dotenv.config();

// AI Provider Configuration
const AI_PROVIDER = process.env.AI_PROVIDER || 'gemini';
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'llama2';
const HUGGINGFACE_API_KEY = process.env.HUGGINGFACE_API_KEY;
const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
const GEMINI_MODEL = process.env.GEMINI_MODEL || 'gemini-pro';

// Parse command line arguments
const args = process.argv.slice(2);
let PORT = 5001; // Default port

// Ki·ªÉm tra bi·∫øn m√¥i tr∆∞·ªùng PLUGIN_PORT tr∆∞·ªõc ti√™n
if (process.env.PLUGIN_PORT) {
  const envPort = parseInt(process.env.PLUGIN_PORT, 10);
  if (!isNaN(envPort)) {
    PORT = envPort;
    console.log(\`Using port \${PORT} from environment variable PLUGIN_PORT\`);
  }
}

// Look for --port argument (∆∞u ti√™n cao h∆°n bi·∫øn m√¥i tr∆∞·ªùng)
for (let i = 0; i < args.length; i++) {
  const arg = args[i];
  if (arg.startsWith('--port=')) {
    const portStr = arg.split('=')[1];
    const portNum = parseInt(portStr, 10);
    if (!isNaN(portNum)) {
      PORT = portNum;
      console.log(\`Using port \${PORT} from command line argument\`);
    }
  }
}

let client;
let messageQueue = [];
let connected = false;

// Connect to the editor
function connectToEditor() {
  client = new net.Socket();

  // Th√™m x·ª≠ l√Ω l·ªói k·∫øt n·ªëi
  let connectionAttempts = 0;
  const MAX_ATTEMPTS = 10;
  const RETRY_DELAY = 5000; // 5 gi√¢y

  // H√†m th·ª≠ k·∫øt n·ªëi v·ªõi x·ª≠ l√Ω l·ªói
  function attemptConnection() {
    if (connectionAttempts >= MAX_ATTEMPTS) {
      console.error(\`Failed to connect after \${MAX_ATTEMPTS} attempts. Giving up.\`);
      return;
    }

    connectionAttempts++;
    console.log(\`Connection attempt \${connectionAttempts}/\${MAX_ATTEMPTS} to port \${PORT}...\`);

    try {
      client.connect(PORT, '127.0.0.1', () => {
        console.log(\`Connected to editor on port \${PORT}\`);
        connectionAttempts = 0; // Reset counter on successful connection
        connected = true;

        // Process any queued messages
        while (messageQueue.length > 0) {
          const message = messageQueue.shift();
          client.write(JSON.stringify(message));
        }

        // Register plugin
        client.write(JSON.stringify({
          type: 'REGISTER_PLUGIN',
          payload: {
            name: 'ai-assistant',
            version: '1.0.0',
            description: 'AI Assistant plugin for Text Editor',
            author: 'nhtam'
          }
        }));

        // Register menu items
        client.write(JSON.stringify({
          type: 'REGISTER_MENU',
          payload: {
            pluginName: 'ai-assistant',
            menuItems: [
              {
                id: 'ai-assistant.completeCode',
                label: 'Complete Code',
                parentMenu: 'edit',
                accelerator: 'Alt+C'
              },
              {
                id: 'ai-assistant.explainCode',
                label: 'Explain Code',
                parentMenu: 'edit',
                accelerator: 'Alt+E'
              },
              {
                id: 'ai-assistant.generateCode',
                label: 'Generate Code',
                parentMenu: 'edit',
                accelerator: 'Alt+G'
              },
              {
                id: 'ai-assistant.aiChat',
                label: 'AI Chat',
                parentMenu: 'view',
                accelerator: 'Alt+A'
              }
            ]
          }
        }));
      });
    } catch (error) {
      console.error('Connection error (1):', error);
      connected = false;
      scheduleRetry();
    }
  }

  function scheduleRetry() {
    console.log(\`Scheduling retry in \${RETRY_DELAY / 1000} seconds...\`);
    setTimeout(attemptConnection, RETRY_DELAY);
  }

  client.on('data', (data) => {
    try {
      const messages = data.toString().split('\\n').filter(Boolean);

      for (const messageStr of messages) {
        if (messageStr.trim()) {
          const message = JSON.parse(messageStr.trim());
          handleMessage(message);
        }
      }
    } catch (error) {
      console.error('Error parsing message:', error);
    }
  });

  client.on('close', () => {
    console.log('Connection closed');
    connected = false;
    scheduleRetry();
  });

  client.on('error', (error) => {
    if (error.code === 'ECONNREFUSED') {
      console.error(\`Connection refused on port \${PORT}. The editor might not be running or using a different port.\`);
    } else {
      console.error('Connection error:', error);
    }
    connected = false;

    // ƒê√≥ng socket hi·ªán t·∫°i ƒë·ªÉ tr√°nh r√≤ r·ªâ b·ªô nh·ªõ
    try {
      client.destroy();
    } catch (destroyError) {
      console.error('Error destroying socket:', destroyError);
    }
  });

  // B·∫Øt ƒë·∫ßu qu√° tr√¨nh k·∫øt n·ªëi
  attemptConnection();
}

// Handle incoming messages
function handleMessage(message) {
  console.log('Received message:', message.type);

  switch (message.type) {
    case 'EXECUTE':
      handleExecute(message);
      break;
    case 'MENU_ACTION':
      handleMenuAction(message);
      break;
    default:
      console.log('Unknown message type:', message.type);
  }
}

// Send a response
function sendResponse(id, success, message, data = {}) {
  const response = {
    id,
    success,
    message,
    data
  };

  if (connected) {
    client.write(JSON.stringify(response));
  } else {
    messageQueue.push(response);
  }
}

// Handle execute message
async function handleExecute(message) {
  const { content, filePath, options } = message.payload;

  console.log('Executing AI Assistant plugin with content length:', content?.length || 0);
  console.log('File path:', filePath || 'none');

  try {
    // Process the content based on options
    const result = await processWithAI(content, options);

    // Send response
    sendResponse(message.id, true, 'AI processing completed', { result });
  } catch (error) {
    console.error('Error processing with AI:', error);
    sendResponse(message.id, false, \`Error: \${error.message}\`);
  }
}

// Handle menu action
async function handleMenuAction(message) {
  const { menuItemId, content, filePath } = message.payload;
  console.log('Executing menu action:', menuItemId);

  try {
    let result = '';
    let options = {};

    switch (menuItemId) {
      case 'ai-assistant.completeCode':
        options = {
          prompt: 'Complete the following code:',
          systemPrompt: 'You are a helpful coding assistant. Complete the code below in the same style and language. Only provide the completed code, no explanations.'
        };
        result = await processWithAI(content, options);
        break;

      case 'ai-assistant.explainCode':
        options = {
          prompt: 'Explain the following code:',
          systemPrompt: 'You are a helpful coding assistant. Explain the following code in detail, including what it does and how it works.'
        };
        result = await processWithAI(content, options);
        break;

      case 'ai-assistant.generateCode':
        options = {
          prompt: 'Generate code based on the description:',
          systemPrompt: 'You are a helpful coding assistant. Generate clean, well-commented code based on the user description.'
        };
        result = await processWithAI(content, options);
        break;

      case 'ai-assistant.aiChat':
        options = {
          prompt: 'Chat with AI:',
          systemPrompt: 'You are a helpful AI assistant. Provide helpful and accurate responses.'
        };
        result = await processWithAI(content, options);
        break;

      default:
        throw new Error(\`Unknown menu item: \${menuItemId}\`);
    }

    // Send response with the result
    sendResponse(message.id, true, 'AI processing completed', { result });
  } catch (error) {
    console.error('Error handling menu action:', error);
    sendResponse(message.id, false, \`Error: \${error.message}\`);
  }
}`;

// Th√™m ph·∫ßn AI processing functions
const aiProcessingFunctions = `

// Process content with AI
async function processWithAI(content, options = {}) {
  try {
    switch (AI_PROVIDER.toLowerCase()) {
      case 'openai':
        return await processWithOpenAI(content, options);
      case 'ollama':
        return await processWithOllama(content, options);
      case 'huggingface':
        return await processWithHuggingFace(content, options);
      case 'gemini':
        return await processWithGemini(content, options);
      default:
        // Default to Gemini as it's free with API limits
        return await processWithGemini(content, options);
    }
  } catch (error) {
    console.error(\`\${AI_PROVIDER} API error:\`, error.response?.data || error.message);
    throw new Error(\`Failed to process with \${AI_PROVIDER}: \` + (error.response?.data?.error?.message || error.message));
  }
}

// Process with OpenAI
async function processWithOpenAI(content, options = {}) {
  if (!OPENAI_API_KEY) {
    throw new Error('OpenAI API key not configured');
  }

  const model = options.model || 'gpt-3.5-turbo';

  const response = await axios.post(
    'https://api.openai.com/v1/chat/completions',
    {
      model,
      messages: [
        {
          role: 'system',
          content: options.systemPrompt || 'You are a helpful coding assistant.'
        },
        {
          role: 'user',
          content: \`\${options.prompt || ''}\n\n\${content}\`
        }
      ],
      max_tokens: options.maxTokens || 2000,
      temperature: options.temperature || 0.7
    },
    {
      headers: {
        'Authorization': \`Bearer \${OPENAI_API_KEY}\`,
        'Content-Type': 'application/json'
      }
    }
  );

  return response.data.choices[0].message.content;
}

// Process with Ollama
async function processWithOllama(content, options = {}) {
  const model = options.model || OLLAMA_MODEL;

  const response = await axios.post(
    \`\${OLLAMA_BASE_URL}/api/generate\`,
    {
      model,
      prompt: \`\${options.systemPrompt || 'You are a helpful coding assistant.'}\n\n\${options.prompt || ''}\n\n\${content}\`,
      stream: false,
      options: {
        temperature: options.temperature || 0.7,
        num_predict: options.maxTokens || 2000
      }
    }
  );

  return response.data.response;
}

// Process with Hugging Face
async function processWithHuggingFace(content, options = {}) {
  if (!HUGGINGFACE_API_KEY) {
    throw new Error('Hugging Face API key not configured');
  }

  const model = options.model || 'microsoft/DialoGPT-medium';

  const response = await axios.post(
    \`https://api-inference.huggingface.co/models/\${model}\`,
    {
      inputs: \`\${options.systemPrompt || 'You are a helpful coding assistant.'}\n\n\${options.prompt || ''}\n\n\${content}\`,
      parameters: {
        max_length: options.maxTokens || 2000,
        temperature: options.temperature || 0.7
      }
    },
    {
      headers: {
        'Authorization': \`Bearer \${HUGGINGFACE_API_KEY}\`,
        'Content-Type': 'application/json'
      }
    }
  );

  return response.data[0].generated_text;
}

// Process with Google Gemini
async function processWithGemini(content, options = {}) {
  try {
    const model = options.model || GEMINI_MODEL;

    // N·∫øu c√≥ GEMINI_API_KEY, s·ª≠ d·ª•ng tr·ª±c ti·∫øp
    if (GEMINI_API_KEY) {
      console.log('üîë Using direct Gemini API');

      const response = await axios.post(
        \`https://generativelanguage.googleapis.com/v1beta/models/\${model}:generateContent?key=\${GEMINI_API_KEY}\`,
        {
          contents: [
            {
              parts: [
                { text: \`\${options.systemPrompt || 'You are a helpful coding assistant.'}\n\n\${options.prompt || ''}\n\n\${content}\` }
              ]
            }
          ],
          generationConfig: {
            temperature: options.temperature || 0.7,
            maxOutputTokens: options.maxTokens || 2000
          }
        }
      );

      return response.data.candidates[0].content.parts[0].text;
    } else {
      // Fallback to mock response n·∫øu kh√¥ng c√≥ API key
      console.log('ü§ñ Using mock AI response (no API key configured)');

      const mockResponses = {
        'complete': \`// Completed code
function helloWorld() {
    console.log("Hello, World!");
    return "Hello, World!";
}

// Usage example:
helloWorld();\`,
        'explain': \`This code defines a simple function that:
1. Prints "Hello, World!" to the console
2. Returns the string "Hello, World!"
3. Can be called to execute both actions\`,
        'generate': \`// Generated code based on your request
function processData(data) {
    // Validate input
    if (!data || typeof data !== 'object') {
        throw new Error('Invalid data provided');
    }

    // Process the data
    const result = Object.keys(data).map(key => ({
        key: key,
        value: data[key],
        processed: true
    }));

    return result;
}

// Example usage:
const sampleData = { name: 'John', age: 30 };
const processed = processData(sampleData);
console.log(processed);\`,
        'chat': \`Hello! I'm your AI assistant. I can help you with:
- Writing and completing code
- Explaining code functionality
- Generating new code based on requirements
- Answering programming questions
- Code optimization and best practices

What would you like help with today?\`
      };

      // Determine response type based on content/prompt
      let responseType = 'chat';
      if (options.prompt?.toLowerCase().includes('complete')) responseType = 'complete';
      else if (options.prompt?.toLowerCase().includes('explain')) responseType = 'explain';
      else if (options.prompt?.toLowerCase().includes('generate')) responseType = 'generate';

      return mockResponses[responseType];
    }
  } catch (error) {
    console.error('Error processing with Gemini:', error.response?.data || error.message);
    throw new Error('Failed to process with Gemini: ' + (error.response?.data?.error || error.message));
  }
}

// Start the plugin
connectToEditor();
`;

fs.writeFileSync(path.join(tempDir, 'index.js'), indexJs + aiProcessingFunctions);

console.log('‚ö° ƒê√£ th√™m AI processing functions ho√†n ch·ªânh!');

console.log('üìÑ T·∫°o c√°c file c·∫•u h√¨nh...');

// T·∫°o README.md
const readmeContent = `# AI Assistant Plugin

M·ªôt plugin AI m·∫°nh m·∫Ω cho Text Editor v·ªõi kh·∫£ nƒÉng:

## üöÄ T√≠nh nƒÉng

- **Complete Code** (Alt+C): Ho√†n th√†nh code t·ª± ƒë·ªông
- **Explain Code** (Alt+E): Gi·∫£i th√≠ch code chi ti·∫øt
- **Generate Code** (Alt+G): T·∫°o code t·ª´ m√¥ t·∫£
- **AI Chat** (Alt+A): Tr√≤ chuy·ªán v·ªõi AI

## ü§ñ AI Providers H·ªó tr·ª£

- **Google Gemini** (M·∫∑c ƒë·ªãnh - Mi·ªÖn ph√≠ v·ªõi gi·ªõi h·∫°n)
- **OpenAI GPT** (C·∫ßn API key)
- **Ollama** (Local AI)
- **Hugging Face** (C·∫ßn API key)

## ‚öôÔ∏è C·∫•u h√¨nh

T·∫°o file \`.env\` v·ªõi n·ªôi dung:

\`\`\`
# AI Provider (gemini, openai, ollama, huggingface)
AI_PROVIDER=gemini

# Gemini API Key (t√πy ch·ªçn - n·∫øu kh√¥ng c√≥ s·∫Ω d√πng mock response)
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API Key (n·∫øu d√πng OpenAI)
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (n·∫øu d√πng Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Hugging Face API Key (n·∫øu d√πng Hugging Face)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here
\`\`\`

## üéØ C√°ch s·ª≠ d·ª•ng

1. Plugin s·∫Ω t·ª± ƒë·ªông k·∫øt n·ªëi v·ªõi Text Editor
2. S·ª≠ d·ª•ng c√°c ph√≠m t·∫Øt ho·∫∑c menu ƒë·ªÉ truy c·∫≠p t√≠nh nƒÉng AI
3. N·∫øu kh√¥ng c√≥ API key, plugin s·∫Ω s·ª≠ d·ª•ng mock responses ƒë·ªÉ demo

## üîß Y√™u c·∫ßu

- Node.js 14.0+
- Text Editor v·ªõi plugin support
- K·∫øt n·ªëi internet (cho real AI APIs)

## üìù Ghi ch√∫

- Plugin ho·∫°t ƒë·ªông v·ªõi ho·∫∑c kh√¥ng c√≥ API keys
- Mock responses ƒë∆∞·ª£c cung c·∫•p ƒë·ªÉ test v√† demo
- H·ªó tr·ª£ auto-reconnect khi m·∫•t k·∫øt n·ªëi
`;

fs.writeFileSync(path.join(tempDir, 'README.md'), readmeContent);

// T·∫°o .env.example
const envExample = `# AI Provider Configuration
AI_PROVIDER=gemini
GEMINI_MODEL=gemini-pro

# API Keys (t√πy ch·ªçn)
GEMINI_API_KEY=your_gemini_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2

# Plugin Configuration
NODE_ENV=production
`;

fs.writeFileSync(path.join(tempDir, '.env.example'), envExample);

// T·∫°o start.bat
const startBat = `@echo off
echo Starting AI Assistant Plugin...
echo.
echo Plugin Features:
echo - Complete Code (Alt+C)
echo - Explain Code (Alt+E)
echo - Generate Code (Alt+G)
echo - AI Chat (Alt+A)
echo.
node index.js --port=5001
`;

fs.writeFileSync(path.join(tempDir, 'start.bat'), startBat);

console.log('‚úÖ ƒê√£ t·∫°o t·∫•t c·∫£ files c·∫ßn thi·∫øt');

// T·∫°o file zip
console.log('üóúÔ∏è ƒê√≥ng g√≥i th√†nh file ZIP...');
try {
  // X√≥a file zip c≈© n·∫øu t·ªìn t·∫°i
  if (fs.existsSync(zipFilePath)) {
    fs.unlinkSync(zipFilePath);
  }

  // S·ª≠ d·ª•ng PowerShell ƒë·ªÉ t·∫°o file zip
  const command = `powershell -command "Compress-Archive -Path '${tempDir}\\*' -DestinationPath '${zipFilePath}'"`;
  execSync(command);

  console.log(`üéâ ƒê√£ t·∫°o file zip th√†nh c√¥ng: ${zipFilePath}`);

  // Hi·ªÉn th·ªã th√¥ng tin file
  const stats = fs.statSync(zipFilePath);
  console.log(`üìä K√≠ch th∆∞·ªõc file: ${(stats.size / 1024 / 1024).toFixed(2)} MB`);

} catch (error) {
  console.error('‚ùå L·ªói khi t·∫°o file zip:', error);
}

// X√≥a th∆∞ m·ª•c t·∫°m th·ªùi
console.log('üßπ X√≥a th∆∞ m·ª•c t·∫°m th·ªùi...');
fs.rmSync(tempDir, { recursive: true, force: true });

console.log('');
console.log('üéä HO√ÄN T·∫§T ƒê√ìNG G√ìI AI ASSISTANT PLUGIN!');
console.log('');
console.log('üìã Th√¥ng tin plugin:');
console.log(`   - T√™n: ${pluginName}`);
console.log(`   - Phi√™n b·∫£n: ${pluginVersion}`);
console.log(`   - File: ${zipFileName}`);
console.log('');
console.log('üöÄ Plugin ƒë√£ s·∫µn s√†ng ƒë·ªÉ upload l√™n Firebase Storage!');
console.log('');
console.log('üí° T√≠nh nƒÉng ho√†n ch·ªânh:');
console.log('   ‚úÖ K·∫øt n·ªëi v·ªõi text editor');
console.log('   ‚úÖ 4 menu items AI (Complete, Explain, Generate, Chat)');
console.log('   ‚úÖ H·ªó tr·ª£ 4 AI providers (Gemini, OpenAI, Ollama, HuggingFace)');
console.log('   ‚úÖ Mock responses khi kh√¥ng c√≥ API key');
console.log('   ‚úÖ Auto-reconnect v√† error handling');
console.log('   ‚úÖ Environment configuration');
console.log('   ‚úÖ Comprehensive documentation');
console.log('');
console.log('üîë ƒê·ªÉ s·ª≠ d·ª•ng real AI:');
console.log('   1. T·∫°o file .env trong th∆∞ m·ª•c plugin');
console.log('   2. Th√™m API key t∆∞∆°ng ·ª©ng');
console.log('   3. Restart plugin');
console.log('');
